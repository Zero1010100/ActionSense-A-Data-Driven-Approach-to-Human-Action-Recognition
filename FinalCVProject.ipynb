{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalCVProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWTFZpoe78zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXTRACTING FRAMES\n",
        "\n",
        "import csv\n",
        "import glob\n",
        "import os.path\n",
        "from subprocess import call\n",
        "import os\n",
        "\n",
        "def extract_files():\n",
        "    data_file = []\n",
        "    folders = ['train','test']\n",
        "    for folder in folders:\n",
        "        class_folders = glob.glob(os.path.join(folder, '*'))\n",
        "\n",
        "        for vid_class in class_folders:\n",
        "            class_files = glob.glob(os.path.join(vid_class, '*.avi'))\n",
        "\n",
        "            for video_path in class_files:\n",
        "                # Get the parts of the file.\n",
        "                video_parts = get_video_parts(video_path)\n",
        "\n",
        "                train_or_test, classname, filename_no_ext, filename = video_parts\n",
        "\n",
        "                # Only extract if we haven't done it yet. Otherwise, just get\n",
        "                # the info.\n",
        "                if not check_already_extracted(video_parts):\n",
        "                    # Now extract it.\n",
        "                    src = os.path.join(train_or_test, classname, filename)\n",
        "                    dest = os.path.join(train_or_test, classname,\n",
        "                        filename_no_ext + '-%04d.jpg')\n",
        "                    call([\"ffmpeg\", \"-i\", src, dest])\n",
        "\n",
        "                # Now get how many frames it is.\n",
        "                nb_frames = get_nb_frames_for_video(video_parts)\n",
        "\n",
        "                data_file.append([train_or_test, classname, filename_no_ext, nb_frames])\n",
        "\n",
        "                #print(\"Generated %d frames for %s\" % (nb_frames, filename_no_ext))\n",
        "\n",
        "    with open('data_file.csv', 'w') as fout:\n",
        "        writer = csv.writer(fout)\n",
        "        writer.writerows(data_file)\n",
        "    #[train|test], class, filename, nb frames\n",
        "    print(\"Extracted and wrote %d video files.\" % (len(data_file)))\n",
        "\n",
        "def get_nb_frames_for_video(video_parts):\n",
        "    train_or_test, classname, filename_no_ext, _ = video_parts\n",
        "    generated_files = glob.glob(os.path.join(train_or_test, classname,\n",
        "                                filename_no_ext + '*.jpg'))\n",
        "    return len(generated_files)\n",
        "\n",
        "def get_video_parts(video_path):\n",
        "    parts = video_path.split(os.path.sep)\n",
        "    filename = parts[2]\n",
        "    filename_no_ext = filename.split('.')[0]\n",
        "    classname = parts[1]\n",
        "    train_or_test = parts[0]\n",
        "\n",
        "    return train_or_test, classname, filename_no_ext, filename\n",
        "\n",
        "def check_already_extracted(video_parts):\n",
        "    train_or_test, classname, filename_no_ext, _ = video_parts\n",
        "    return bool(os.path.exists(os.path.join(train_or_test, classname,\n",
        "                               filename_no_ext + '-0001.jpg')))\n",
        "\n",
        "extract_files()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf64XB5A9prf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import os.path\n",
        "import sys\n",
        "import operator\n",
        "import threading\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "class DataSet():\n",
        "\n",
        "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
        "        self.seq_length = seq_length\n",
        "        self.class_limit = class_limit\n",
        "        self.sequence_path = os.path.join('data', 'sequences')\n",
        "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
        "        self.data = self.get_data()\n",
        "        self.classes = self.get_classes()\n",
        "        self.data = self.clean_data()\n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    @staticmethod\n",
        "    def get_data():\n",
        "        with open(os.path.join('data', 'data_file.csv'), 'r') as fin:\n",
        "            reader = csv.reader(fin)\n",
        "            data = list(reader)\n",
        "        return data\n",
        "\n",
        "    def clean_data(self):\n",
        "        data_clean = []\n",
        "        for item in self.data:\n",
        "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
        "                    and item[1] in self.classes:\n",
        "                data_clean.append(item)\n",
        "\n",
        "        return data_clean\n",
        "\n",
        "    def get_classes(self):\n",
        "        classes = []\n",
        "        for item in self.data:\n",
        "            if item[1] not in classes:\n",
        "                classes.append(item[1])\n",
        "        classes = sorted(classes)\n",
        "        if self.class_limit is not None:\n",
        "            return classes[:self.class_limit]\n",
        "        else:\n",
        "            return classes\n",
        "\n",
        "    def get_class_one_hot(self, class_str):\n",
        "        # Encode it first.\n",
        "        label_encoded = self.classes.index(class_str)\n",
        "        # Now one-hot it.\n",
        "        label_hot = to_categorical(label_encoded, len(self.classes))\n",
        "        assert len(label_hot) == len(self.classes)\n",
        "        return label_hot\n",
        "\n",
        "    def split_train_test(self):\n",
        "        train = []\n",
        "        test = []\n",
        "        for item in self.data:\n",
        "            if item[0] == 'train':\n",
        "                train.append(item)\n",
        "            else:\n",
        "                test.append(item)\n",
        "        return train, test\n",
        "\n",
        "    def get_all_sequences_in_memory(self, train_test, data_type):\n",
        "        train, test = self.split_train_test()\n",
        "        data = train if train_test == 'train' else test\n",
        "\n",
        "        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
        "\n",
        "        X, y = [], []\n",
        "        for row in data:\n",
        "            sequence = self.get_extracted_sequence(data_type, row)\n",
        "            if sequence is None:\n",
        "                print(\"Can't find sequence. Did you generate them?\")\n",
        "                raise\n",
        "            X.append(sequence)\n",
        "            y.append(self.get_class_one_hot(row[1]))\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def get_extracted_sequence(self, data_type, sample):\n",
        "        filename = sample[2]\n",
        "        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n",
        "            '-' + data_type + '.npy')\n",
        "        if os.path.isfile(path):\n",
        "            return np.load(path)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_frames_by_filename(self, filename, data_type):\n",
        "        sample = None\n",
        "        for row in self.data:\n",
        "            if row[2] == filename:\n",
        "                sample = row\n",
        "                break\n",
        "        if sample is None:\n",
        "            raise ValueError(\"Couldn't find sample: %s\" % filename)\n",
        "        sequence = self.get_extracted_sequence(data_type, sample)\n",
        "        if sequence is None:\n",
        "            raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
        "        return sequence\n",
        "\n",
        "    @staticmethod\n",
        "    def get_frames_for_sample(sample):\n",
        "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
        "        filenames.\"\"\"\n",
        "        path = os.path.join('data', sample[0], sample[1])\n",
        "        filename = sample[2]\n",
        "        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
        "        return images\n",
        "\n",
        "    @staticmethod\n",
        "    def rescale_list(input_list, size):\n",
        "        assert len(input_list) >= size\n",
        "        skip = len(input_list) // size\n",
        "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
        "        return output[:size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH2FCn0X9rU4",
        "colab_type": "code",
        "outputId": "7d888dc8-136a-49d7-c652-e3c4daafd739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import os.path\n",
        "from keras.preprocessing import image as Img\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Get the dataset.\n",
        "data = DataSet(seq_length=40, class_limit=70)\n",
        "\n",
        "base_model = InceptionV3(\n",
        "    weights='imagenet',\n",
        "    include_top=True\n",
        ")\n",
        "# We'll extract features at the final pool layer.\n",
        "model = Model(\n",
        "    inputs=base_model.input,\n",
        "    outputs=base_model.get_layer('avg_pool').output\n",
        ")\n",
        "\n",
        "# Loop through data.\n",
        "pbar = tqdm(total=len(data.data))\n",
        "for video in data.data:\n",
        "\n",
        "    # Get the path to the sequence for this video.\n",
        "    path = os.path.join('data', 'sequences', video[2] + '-' + str(seq_length) + \\\n",
        "        '-features')  # numpy will auto-append .npy\n",
        "    # Check if we already have it.\n",
        "    if os.path.isfile(path + '.npy'):\n",
        "        pbar.update(1)\n",
        "        continue\n",
        "\n",
        "    # Get the frames for this video.\n",
        "    frames = data.get_frames_for_sample(video)\n",
        "    #print(frames)\n",
        "\n",
        "    # Now downsample to just the ones we need.\n",
        "    frames = data.rescale_list(frames, 40)\n",
        "    #print(frames)\n",
        "    #extracting features and appending to build the sequence.\n",
        "    sequence = []\n",
        "    for image in frames:\n",
        "        img = Img.load_img(image, target_size=(299, 299))\n",
        "        x = Img.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        features = model.predict(x)\n",
        "        sequence.append(features[0])\n",
        "\n",
        "    # Save the sequence.\n",
        "    np.save(path, sequence)\n",
        "\n",
        "    pbar.update(1)\n",
        "\n",
        "pbar.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/8380 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 97/8380 [00:00<00:08, 959.67it/s]\u001b[A\n",
            "  2%|▏         | 204/8380 [00:00<00:08, 988.29it/s]\u001b[A\n",
            "  4%|▎         | 297/8380 [00:00<00:08, 968.95it/s]\u001b[A\n",
            "  5%|▍         | 405/8380 [00:00<00:07, 999.27it/s]\u001b[A\n",
            "  6%|▌         | 497/8380 [00:00<00:08, 973.11it/s]\u001b[A\n",
            "  7%|▋         | 600/8380 [00:00<00:07, 987.89it/s]\u001b[A\n",
            "  8%|▊         | 694/8380 [00:00<00:07, 971.42it/s]\u001b[A\n",
            " 10%|▉         | 805/8380 [00:00<00:07, 1008.84it/s]\u001b[A\n",
            " 11%|█         | 918/8380 [00:00<00:07, 1040.46it/s]\u001b[A\n",
            " 12%|█▏        | 1030/8380 [00:01<00:06, 1060.86it/s]\u001b[A\n",
            " 14%|█▎        | 1143/8380 [00:01<00:06, 1077.78it/s]\u001b[A\n",
            " 15%|█▍        | 1255/8380 [00:01<00:06, 1086.86it/s]\u001b[A\n",
            " 16%|█▋        | 1363/8380 [00:01<00:06, 1075.66it/s]\u001b[A\n",
            " 18%|█▊        | 1470/8380 [00:01<00:06, 1068.61it/s]\u001b[A\n",
            " 19%|█▉        | 1577/8380 [00:01<00:06, 1063.39it/s]\u001b[A\n",
            " 20%|██        | 1689/8380 [00:01<00:06, 1077.39it/s]\u001b[A\n",
            " 21%|██▏       | 1797/8380 [00:01<00:06, 1006.53it/s]\u001b[A\n",
            " 23%|██▎       | 1908/8380 [00:01<00:06, 1033.57it/s]\u001b[A\n",
            " 24%|██▍       | 2013/8380 [00:01<00:06, 1004.42it/s]\u001b[A\n",
            " 25%|██▌       | 2123/8380 [00:02<00:06, 1030.47it/s]\u001b[A\n",
            " 27%|██▋       | 2231/8380 [00:02<00:05, 1044.81it/s]\u001b[A\n",
            " 28%|██▊       | 2336/8380 [00:02<00:06, 996.68it/s] \u001b[A\n",
            " 29%|██▉       | 2437/8380 [00:02<00:06, 950.78it/s]\u001b[A\n",
            " 30%|███       | 2534/8380 [00:02<00:06, 919.53it/s]\u001b[A\n",
            " 31%|███▏      | 2627/8380 [00:02<00:06, 907.18it/s]\u001b[A\n",
            " 32%|███▏      | 2719/8380 [00:02<00:06, 891.09it/s]\u001b[A\n",
            " 34%|███▎      | 2813/8380 [00:02<00:06, 903.30it/s]\u001b[A\n",
            " 35%|███▍      | 2924/8380 [00:02<00:05, 955.57it/s]\u001b[A\n",
            " 36%|███▌      | 3035/8380 [00:03<00:05, 996.15it/s]\u001b[A\n",
            " 37%|███▋      | 3136/8380 [00:03<00:05, 985.10it/s]\u001b[A\n",
            " 39%|███▊      | 3241/8380 [00:03<00:05, 1002.32it/s]\u001b[A\n",
            " 40%|███▉      | 3342/8380 [00:03<00:05, 950.95it/s] \u001b[A\n",
            " 41%|████      | 3439/8380 [00:03<00:05, 956.11it/s]\u001b[A\n",
            " 42%|████▏     | 3546/8380 [00:03<00:04, 984.85it/s]\u001b[A\n",
            " 44%|████▎     | 3657/8380 [00:03<00:04, 1018.72it/s]\u001b[A\n",
            " 45%|████▍     | 3766/8380 [00:03<00:04, 1037.50it/s]\u001b[A\n",
            " 46%|████▌     | 3871/8380 [00:03<00:04, 1021.45it/s]\u001b[A\n",
            " 48%|████▊     | 3984/8380 [00:03<00:04, 1049.90it/s]\u001b[A\n",
            " 49%|████▉     | 4095/8380 [00:04<00:04, 1066.48it/s]\u001b[A\n",
            " 50%|█████     | 4207/8380 [00:04<00:03, 1080.99it/s]\u001b[A\n",
            " 52%|█████▏    | 4316/8380 [00:04<00:03, 1078.56it/s]\u001b[A\n",
            " 53%|█████▎    | 4425/8380 [00:04<00:03, 1061.10it/s]\u001b[A\n",
            " 54%|█████▍    | 4532/8380 [00:04<00:03, 1012.42it/s]\u001b[A\n",
            " 55%|█████▌    | 4637/8380 [00:04<00:03, 1021.25it/s]\u001b[A\n",
            " 57%|█████▋    | 4740/8380 [00:04<00:03, 995.11it/s] \u001b[A\n",
            " 58%|█████▊    | 4845/8380 [00:04<00:03, 1009.88it/s]\u001b[A\n",
            " 59%|█████▉    | 4947/8380 [00:04<00:03, 977.87it/s] \u001b[A\n",
            " 60%|██████    | 5053/8380 [00:04<00:03, 999.71it/s]\u001b[A\n",
            " 62%|██████▏   | 5154/8380 [00:05<00:03, 988.72it/s]\u001b[A\n",
            " 63%|██████▎   | 5260/8380 [00:05<00:03, 1007.05it/s]\u001b[A\n",
            " 64%|██████▍   | 5363/8380 [00:05<00:02, 1010.42it/s]\u001b[A\n",
            " 65%|██████▌   | 5465/8380 [00:05<00:03, 969.49it/s] \u001b[A\n",
            " 66%|██████▋   | 5569/8380 [00:05<00:02, 988.16it/s]\u001b[A\n",
            " 68%|██████▊   | 5669/8380 [00:05<00:02, 955.88it/s]\u001b[A\n",
            " 69%|██████▉   | 5766/8380 [00:05<00:02, 941.98it/s]\u001b[A\n",
            " 70%|██████▉   | 5861/8380 [00:05<00:02, 915.84it/s]\u001b[A\n",
            " 71%|███████   | 5970/8380 [00:05<00:02, 961.40it/s]\u001b[A\n",
            " 73%|███████▎  | 6079/8380 [00:06<00:02, 995.23it/s]\u001b[A\n",
            " 74%|███████▍  | 6189/8380 [00:06<00:02, 1022.15it/s]\u001b[A\n",
            " 75%|███████▌  | 6300/8380 [00:06<00:01, 1044.59it/s]\u001b[A\n",
            " 76%|███████▋  | 6406/8380 [00:06<00:01, 1004.24it/s]\u001b[A\n",
            " 78%|███████▊  | 6508/8380 [00:06<00:01, 952.53it/s] \u001b[A\n",
            " 79%|███████▉  | 6612/8380 [00:06<00:01, 975.26it/s]\u001b[A\n",
            " 80%|████████  | 6722/8380 [00:06<00:01, 1007.32it/s]\u001b[A\n",
            " 82%|████████▏ | 6833/8380 [00:06<00:01, 1035.27it/s]\u001b[A\n",
            " 83%|████████▎ | 6938/8380 [00:06<00:01, 1023.06it/s]\u001b[A\n",
            " 84%|████████▍ | 7041/8380 [00:06<00:01, 1015.02it/s]\u001b[A\n",
            " 85%|████████▌ | 7143/8380 [00:07<00:01, 969.10it/s] \u001b[A\n",
            " 86%|████████▋ | 7241/8380 [00:07<00:01, 943.41it/s]\u001b[A\n",
            " 88%|████████▊ | 7337/8380 [00:07<00:01, 925.61it/s]\u001b[A\n",
            " 89%|████████▊ | 7431/8380 [00:07<00:01, 915.05it/s]\u001b[A\n",
            " 90%|████████▉ | 7523/8380 [00:07<00:00, 911.33it/s]\u001b[A\n",
            " 91%|█████████ | 7615/8380 [00:07<00:00, 896.57it/s]\u001b[A\n",
            " 92%|█████████▏| 7705/8380 [00:07<00:00, 895.06it/s]\u001b[A\n",
            " 93%|█████████▎| 7795/8380 [00:07<00:00, 890.03it/s]\u001b[A\n",
            " 94%|█████████▍| 7886/8380 [00:07<00:00, 894.47it/s]\u001b[A\n",
            " 95%|█████████▌| 7991/8380 [00:08<00:00, 935.19it/s]\u001b[A\n",
            " 97%|█████████▋| 8098/8380 [00:08<00:00, 970.91it/s]\u001b[A\n",
            " 98%|█████████▊| 8204/8380 [00:08<00:00, 994.94it/s]\u001b[A\n",
            " 99%|█████████▉| 8308/8380 [00:08<00:00, 1006.81it/s]\u001b[A\n",
            "100%|██████████| 8380/8380 [00:08<00:00, 994.54it/s] \u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNnrcf6n9v8A",
        "colab_type": "code",
        "outputId": "45ff9fc5-b90b-49b7-85f1-40b6c298bfe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from collections import deque\n",
        "import sys\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "import time\n",
        "import os.path\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath=os.path.join('data', 'checkpoints','lstm-features' + '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
        "    verbose=1,\n",
        "    save_best_only=True)\n",
        "\n",
        "# Helper: TensorBoard\n",
        "tb = TensorBoard(log_dir=os.path.join('data', 'logs', 'lstm'))\n",
        "\n",
        "# Helper: Stop when we stop learning.\n",
        "early_stopper = EarlyStopping(patience=10)\n",
        "\n",
        "# Helper: Save results.\n",
        "timestamp = time.time()\n",
        "csv_logger = CSVLogger(os.path.join('data', 'logs', 'lstm' + '-' + 'training-' + \\\n",
        "    str(timestamp) + '.log'))\n",
        "\n",
        "# Get the data and process it.\n",
        "data = DataSet(\n",
        "    seq_length=40,\n",
        "    class_limit=70\n",
        ")\n",
        "#listt=[]\n",
        "#listt2=[]\n",
        "X, y = data.get_all_sequences_in_memory('train', 'features')\n",
        "X_test, y_test = data.get_all_sequences_in_memory('test', 'features')\n",
        "# for i in range(len(X)):\n",
        "#  for j in range(70):\n",
        "  #   if (y[i][j]==1) and not(j in listt):\n",
        "  #    listt.append(j)\n",
        "# for i in range(len(X_test)):\n",
        "#  for j in range(70):\n",
        "  #   if (y_test[i][j]==1) and not(j in listt2):\n",
        "  #    listt2.append(j)\n",
        "#print(listt)\n",
        "#print(listt2)\n",
        "#listt3= []\n",
        "# for i in range(len(listt2)):\n",
        "#  if not(listt2[i] in listt):\n",
        "  #   listt3.append(listt2[i])\n",
        "#X_test2 = X_test.copy()\n",
        "#y_test2 = y_test.copy()\n",
        "#for i in range(len(X_test)):\n",
        "  # flag=1\n",
        "  #for j in range(70):\n",
        "    # if(y_test[i][j]==1) and (j in listt3):\n",
        "    #  flag=0\n",
        "      # break\n",
        "  #if flag==1:\n",
        "    # X_test2 = np.append(X_test2,[X_test[i]],axis=0)\n",
        "    #y_test2 = np.append(y_test2,[y_test[i]],axis=0)\n",
        "#print(X_test2.shape)\n",
        "#print(y_test2.shape)\n",
        "#l = X_test2.shape[0]-X_test.shape[0]\n",
        "#X_test = X_test2[-l:,:,:]\n",
        "#y_test = y_test2[-l:,:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(2048, return_sequences=False,input_shape=(40,2048),dropout=0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(data.classes), activation='softmax'))\n",
        "optimizer = Adam(lr=1e-5, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                    metrics=['accuracy','top_k_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1,\n",
        "    callbacks=[tb, early_stopper, csv_logger,checkpointer],\n",
        "    epochs=100)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n",
            "Loading 5980 samples into memory for training.\n",
            "Loading 2400 samples into memory for testing.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2048)              33562624  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 70)                35910     \n",
            "=================================================================\n",
            "Total params: 34,647,622\n",
            "Trainable params: 34,647,622\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 5980 samples, validate on 2400 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/100\n",
            "5980/5980 [==============================] - 100s 17ms/step - loss: 4.1754 - acc: 0.0401 - top_k_categorical_accuracy: 0.1493 - val_loss: 3.8996 - val_acc: 0.2487 - val_top_k_categorical_accuracy: 0.4592\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.89964, saving model to data/checkpoints/lstm-features.001-3.900.hdf5\n",
            "Epoch 2/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 3.8565 - acc: 0.1360 - top_k_categorical_accuracy: 0.3263 - val_loss: 3.3664 - val_acc: 0.3583 - val_top_k_categorical_accuracy: 0.6217\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.89964 to 3.36643, saving model to data/checkpoints/lstm-features.002-3.366.hdf5\n",
            "Epoch 3/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 3.4102 - acc: 0.2390 - top_k_categorical_accuracy: 0.4870 - val_loss: 2.6017 - val_acc: 0.4354 - val_top_k_categorical_accuracy: 0.7271\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.36643 to 2.60169, saving model to data/checkpoints/lstm-features.003-2.602.hdf5\n",
            "Epoch 4/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 2.8540 - acc: 0.3334 - top_k_categorical_accuracy: 0.6060 - val_loss: 2.0285 - val_acc: 0.4992 - val_top_k_categorical_accuracy: 0.7858\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.60169 to 2.02853, saving model to data/checkpoints/lstm-features.004-2.029.hdf5\n",
            "Epoch 5/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 2.4349 - acc: 0.4089 - top_k_categorical_accuracy: 0.7018 - val_loss: 1.7415 - val_acc: 0.5379 - val_top_k_categorical_accuracy: 0.8221\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.02853 to 1.74155, saving model to data/checkpoints/lstm-features.005-1.742.hdf5\n",
            "Epoch 6/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 2.1017 - acc: 0.4612 - top_k_categorical_accuracy: 0.7594 - val_loss: 1.5153 - val_acc: 0.5833 - val_top_k_categorical_accuracy: 0.8633\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.74155 to 1.51526, saving model to data/checkpoints/lstm-features.006-1.515.hdf5\n",
            "Epoch 7/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.8653 - acc: 0.5176 - top_k_categorical_accuracy: 0.8050 - val_loss: 1.3882 - val_acc: 0.6075 - val_top_k_categorical_accuracy: 0.8729\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.51526 to 1.38820, saving model to data/checkpoints/lstm-features.007-1.388.hdf5\n",
            "Epoch 8/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.6939 - acc: 0.5500 - top_k_categorical_accuracy: 0.8311 - val_loss: 1.3359 - val_acc: 0.6208 - val_top_k_categorical_accuracy: 0.8812\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.38820 to 1.33594, saving model to data/checkpoints/lstm-features.008-1.336.hdf5\n",
            "Epoch 9/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.5661 - acc: 0.5848 - top_k_categorical_accuracy: 0.8487 - val_loss: 1.2537 - val_acc: 0.6492 - val_top_k_categorical_accuracy: 0.8879\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.33594 to 1.25372, saving model to data/checkpoints/lstm-features.009-1.254.hdf5\n",
            "Epoch 10/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.4516 - acc: 0.6030 - top_k_categorical_accuracy: 0.8729 - val_loss: 1.1821 - val_acc: 0.6696 - val_top_k_categorical_accuracy: 0.8975\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.25372 to 1.18210, saving model to data/checkpoints/lstm-features.010-1.182.hdf5\n",
            "Epoch 11/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.3568 - acc: 0.6283 - top_k_categorical_accuracy: 0.8834 - val_loss: 1.1668 - val_acc: 0.6821 - val_top_k_categorical_accuracy: 0.8962\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.18210 to 1.16678, saving model to data/checkpoints/lstm-features.011-1.167.hdf5\n",
            "Epoch 12/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 1.2826 - acc: 0.6482 - top_k_categorical_accuracy: 0.8955 - val_loss: 1.1264 - val_acc: 0.6754 - val_top_k_categorical_accuracy: 0.9025\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.16678 to 1.12635, saving model to data/checkpoints/lstm-features.012-1.126.hdf5\n",
            "Epoch 13/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.2031 - acc: 0.6612 - top_k_categorical_accuracy: 0.9087 - val_loss: 1.1369 - val_acc: 0.6908 - val_top_k_categorical_accuracy: 0.9046\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.12635\n",
            "Epoch 14/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.1432 - acc: 0.6764 - top_k_categorical_accuracy: 0.9166 - val_loss: 1.1143 - val_acc: 0.6925 - val_top_k_categorical_accuracy: 0.9029\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.12635 to 1.11426, saving model to data/checkpoints/lstm-features.014-1.114.hdf5\n",
            "Epoch 15/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 1.0829 - acc: 0.6940 - top_k_categorical_accuracy: 0.9268 - val_loss: 1.0834 - val_acc: 0.6971 - val_top_k_categorical_accuracy: 0.9108\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.11426 to 1.08341, saving model to data/checkpoints/lstm-features.015-1.083.hdf5\n",
            "Epoch 16/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 1.0443 - acc: 0.7018 - top_k_categorical_accuracy: 0.9276 - val_loss: 1.0760 - val_acc: 0.7017 - val_top_k_categorical_accuracy: 0.9163\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.08341 to 1.07600, saving model to data/checkpoints/lstm-features.016-1.076.hdf5\n",
            "Epoch 17/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.9799 - acc: 0.7169 - top_k_categorical_accuracy: 0.9346 - val_loss: 1.0921 - val_acc: 0.7154 - val_top_k_categorical_accuracy: 0.9083\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.07600\n",
            "Epoch 18/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.9360 - acc: 0.7321 - top_k_categorical_accuracy: 0.9433 - val_loss: 1.0815 - val_acc: 0.7150 - val_top_k_categorical_accuracy: 0.9187\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.07600\n",
            "Epoch 19/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.9000 - acc: 0.7391 - top_k_categorical_accuracy: 0.9483 - val_loss: 1.0706 - val_acc: 0.7183 - val_top_k_categorical_accuracy: 0.9196\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.07600 to 1.07058, saving model to data/checkpoints/lstm-features.019-1.071.hdf5\n",
            "Epoch 20/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.8539 - acc: 0.7488 - top_k_categorical_accuracy: 0.9523 - val_loss: 1.0585 - val_acc: 0.7213 - val_top_k_categorical_accuracy: 0.9225\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.07058 to 1.05855, saving model to data/checkpoints/lstm-features.020-1.059.hdf5\n",
            "Epoch 21/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.8171 - acc: 0.7619 - top_k_categorical_accuracy: 0.9564 - val_loss: 1.0292 - val_acc: 0.7350 - val_top_k_categorical_accuracy: 0.9279\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.05855 to 1.02922, saving model to data/checkpoints/lstm-features.021-1.029.hdf5\n",
            "Epoch 22/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.7898 - acc: 0.7756 - top_k_categorical_accuracy: 0.9564 - val_loss: 1.0183 - val_acc: 0.7383 - val_top_k_categorical_accuracy: 0.9304\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.02922 to 1.01830, saving model to data/checkpoints/lstm-features.022-1.018.hdf5\n",
            "Epoch 23/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.7621 - acc: 0.7751 - top_k_categorical_accuracy: 0.9615 - val_loss: 1.0362 - val_acc: 0.7312 - val_top_k_categorical_accuracy: 0.9246\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.01830\n",
            "Epoch 24/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.7285 - acc: 0.7839 - top_k_categorical_accuracy: 0.9627 - val_loss: 1.0244 - val_acc: 0.7292 - val_top_k_categorical_accuracy: 0.9263\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.01830\n",
            "Epoch 25/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.7227 - acc: 0.7876 - top_k_categorical_accuracy: 0.9649 - val_loss: 1.0061 - val_acc: 0.7383 - val_top_k_categorical_accuracy: 0.9283\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.01830 to 1.00608, saving model to data/checkpoints/lstm-features.025-1.006.hdf5\n",
            "Epoch 26/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.6820 - acc: 0.8007 - top_k_categorical_accuracy: 0.9666 - val_loss: 1.0244 - val_acc: 0.7304 - val_top_k_categorical_accuracy: 0.9292\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.00608\n",
            "Epoch 27/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.6419 - acc: 0.8054 - top_k_categorical_accuracy: 0.9721 - val_loss: 1.0213 - val_acc: 0.7371 - val_top_k_categorical_accuracy: 0.9242\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.00608\n",
            "Epoch 28/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.6156 - acc: 0.8144 - top_k_categorical_accuracy: 0.9754 - val_loss: 1.0611 - val_acc: 0.7304 - val_top_k_categorical_accuracy: 0.9246\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.00608\n",
            "Epoch 29/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.5910 - acc: 0.8246 - top_k_categorical_accuracy: 0.9749 - val_loss: 1.0235 - val_acc: 0.7338 - val_top_k_categorical_accuracy: 0.9283\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.00608\n",
            "Epoch 30/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.5732 - acc: 0.8281 - top_k_categorical_accuracy: 0.9766 - val_loss: 1.0287 - val_acc: 0.7354 - val_top_k_categorical_accuracy: 0.9271\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.00608\n",
            "Epoch 31/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.5384 - acc: 0.8400 - top_k_categorical_accuracy: 0.9811 - val_loss: 1.0183 - val_acc: 0.7450 - val_top_k_categorical_accuracy: 0.9279\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.00608\n",
            "Epoch 32/100\n",
            "5980/5980 [==============================] - 98s 16ms/step - loss: 0.5563 - acc: 0.8351 - top_k_categorical_accuracy: 0.9759 - val_loss: 1.0632 - val_acc: 0.7308 - val_top_k_categorical_accuracy: 0.9271\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.00608\n",
            "Epoch 33/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.5110 - acc: 0.8487 - top_k_categorical_accuracy: 0.9824 - val_loss: 1.0515 - val_acc: 0.7533 - val_top_k_categorical_accuracy: 0.9304\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.00608\n",
            "Epoch 34/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.5005 - acc: 0.8485 - top_k_categorical_accuracy: 0.9839 - val_loss: 1.0602 - val_acc: 0.7525 - val_top_k_categorical_accuracy: 0.9313\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.00608\n",
            "Epoch 35/100\n",
            "5980/5980 [==============================] - 97s 16ms/step - loss: 0.4601 - acc: 0.8622 - top_k_categorical_accuracy: 0.9849 - val_loss: 1.0377 - val_acc: 0.7521 - val_top_k_categorical_accuracy: 0.9292\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.00608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f347d3e6908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqzLc5jAA71t",
        "colab_type": "text"
      },
      "source": [
        "To run on a particular kind of videos provided in UCF101:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mja690yUR222",
        "colab_type": "code",
        "outputId": "419d560f-532a-4472-fba9-38f2491e3deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from collections import deque\n",
        "import sys\n",
        "import time\n",
        "import os.path\n",
        "import glob\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(2048, return_sequences=False,input_shape=(40,2048),dropout=0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(70, activation='softmax'))\n",
        "model.load_weights('data/checkpoints/lstm-features.025-1.006.hdf5')\n",
        "print(model.summary())\n",
        "\n",
        "classes = glob.glob(\"data/train/*\")\n",
        "classes = [classes[i].split('/')[2] for i in range(len(classes))]\n",
        "classes = sorted(classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2048)              33562624  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 70)                35910     \n",
            "=================================================================\n",
            "Total params: 34,647,622\n",
            "Trainable params: 34,647,622\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWCc7BRGTUGy",
        "colab_type": "code",
        "outputId": "f1567df2-2706-4477-b23c-50ae315ca1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import os.path\n",
        "from keras.preprocessing import image as Img\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from tqdm import tqdm\n",
        "\n",
        "path= 'UCF101/BoxingSpeedBag/'\n",
        "y = glob.glob(path+'*.avi')\n",
        "for Z in y: \n",
        "  name = (Z.split('/')[2]).split('.')[0]\n",
        "  name = name+'-40-features.npy'\n",
        "  X = glob.glob(\"data/sequences/\"+name)\n",
        "  seq = np.array([[]])\n",
        "  flag=1\n",
        "  for i in X:\n",
        "    tmp = np.load(i)\n",
        "    if flag==1:\n",
        "      seq = tmp\n",
        "    else:\n",
        "      seq = np.append(seq,tmp,0)\n",
        "  seq = np.array([seq])\n",
        "  if(seq.shape != (1,40,2048)):\n",
        "    continue\n",
        "  prediction = model.predict(seq)\n",
        "\n",
        "  maxm = prediction[0][0]\n",
        "  maxid = 0\n",
        "  for i in range(len(prediction[0])):\n",
        "    if(maxm<prediction[0][i]):\n",
        "      maxm = prediction[0][i]\n",
        "      maxid = i\n",
        "\n",
        "  print(Z,' ------- ',classes[maxid])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g01_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g01_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g01_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g02_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g02_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g02_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g02_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g03_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g03_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g03_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g03_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g03_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c05.avi  -------  BlowDryHair\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c06.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g04_c07.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g05_c01.avi  -------  HeadMassage\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g05_c02.avi  -------  BlowDryHair\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g05_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g05_c04.avi  -------  BlowDryHair\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g05_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g06_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g06_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g06_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g06_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g06_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g08_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g08_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g08_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g08_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g08_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g10_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g10_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g10_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g10_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g11_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g11_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g11_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g11_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g11_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g11_c06.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g12_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g12_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g12_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g13_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g13_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g13_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g13_c06.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g14_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g14_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g14_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g14_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g14_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g14_c06.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g15_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g15_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g15_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g15_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g15_c06.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g16_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g16_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g16_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g16_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g16_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g18_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g18_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g18_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g18_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g19_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g19_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g19_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g19_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g19_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g20_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g20_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g20_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g20_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g21_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g21_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g21_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g21_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g22_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g22_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g22_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g22_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g23_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g23_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g23_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g23_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g24_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g24_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g24_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g24_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c02.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c01.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c03.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c04.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c05.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c06.avi  -------  BoxingSpeedBag\n",
            "UCF101/BoxingSpeedBag/v_BoxingSpeedBag_g25_c07.avi  -------  BoxingSpeedBag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4-rO69jAlA8",
        "colab_type": "text"
      },
      "source": [
        "To run the code on a specific video, please upload the video in correct directory and run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLfr8vf__5W7",
        "colab_type": "code",
        "outputId": "9689648f-3d88-47f6-bda8-0dcc9796c6d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from collections import deque\n",
        "import sys\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "import time\n",
        "import os.path\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(2048, return_sequences=False,input_shape=(40,2048),dropout=0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(70, activation='softmax'))\n",
        "model.load_weights('data/checkpoints/lstm-features.025-1.006.hdf5')\n",
        "print(model.summary())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 2048)              33562624  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 70)                35910     \n",
            "=================================================================\n",
            "Total params: 34,647,622\n",
            "Trainable params: 34,647,622\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YyPmds-3oYO",
        "colab_type": "code",
        "outputId": "8b9e240e-185e-4301-c543-022139447378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "import numpy as np\n",
        "import os.path\n",
        "from keras.preprocessing import image as Img\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "import glob\n",
        "\n",
        "def rescale_list(input_list, size):\n",
        "    assert len(input_list) >= size\n",
        "    skip = len(input_list) // size\n",
        "    output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
        "    return output[:size]\n",
        "classes = glob.glob(\"data/train/*\")\n",
        "classes = [classes[i].split('/')[2] for i in range(len(classes))]\n",
        "classes = sorted(classes)\n",
        "\n",
        "import cv2 \n",
        "import os \n",
        "image_name = 'cricket.avi'\n",
        "cam = cv2.VideoCapture(image_name) \n",
        "currentframe = 0\n",
        "  \n",
        "frames=[]\n",
        "while(True): \n",
        "    ret,frame = cam.read() \n",
        "    if ret: \n",
        "        # if video is still left continue creating images \n",
        "        name = 'testFinal/frame'+image_name +\"frame_no\"+ str(currentframe) + '.jpg'\n",
        "        cv2.imwrite(name, frame) \n",
        "        frames.append(name)  \n",
        "        currentframe += 1\n",
        "    else: \n",
        "        break\n",
        "cam.release() \n",
        "cv2.destroyAllWindows() \n",
        "rescaled_list = rescale_list(frames,40)\n",
        "\n",
        "base_model = InceptionV3(\n",
        "    weights='imagenet',\n",
        "    include_top=True\n",
        ")\n",
        "# We'll extract features at the final pool layer.\n",
        "inception_model = Model(\n",
        "    inputs=base_model.input,\n",
        "    outputs=base_model.get_layer('avg_pool').output\n",
        ")\n",
        "sequence = []\n",
        "for image in rescaled_list:\n",
        "        img = Img.load_img(image, target_size=(299, 299))\n",
        "        x = Img.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        features = inception_model.predict(x)\n",
        "        sequence.append(features[0])\n",
        "\n",
        "sequence = np.array([sequence])\n",
        "prediction = model.predict(sequence)\n",
        "maxm = prediction[0][0]\n",
        "maxid = 0\n",
        "for i in range(len(prediction[0])):\n",
        "  if(maxm<prediction[0][i]):\n",
        "    maxm = prediction[0][i]\n",
        "    maxid = i\n",
        "\n",
        "print(image_name,' ------- ',classes[maxid])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 3s 0us/step\n",
            "cricket.avi  -------  CricketBowling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C1ZBYWsleEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}